# -*- coding: utf-8 -*-
"""
Created on Mon Mar 30 16:58:35 2015

@author: Yan
"""

import numpy as np

repers = open('repers_endless.txt', 'w')                     #создание файла
repers.close()

phi0 = [0,  1.36,  -0.49, 0.36]                              #параметры авторегрессионных моделей
phi1 = [0,  1.02,  -0.40, 0.63]                              #последнее число - параметр B, определяющий
phi2 = [0,  0.82,  -0.49, 0.73]                              #                      степень влияния шума
phi3 = [0,  0,     -0.49, 0.87]
phi4 = [0, -0.82,  -0.49, 0.73]
phi = np.array([phi0,phi1,phi2,phi3,phi4])
n = 2                                                        #порядок авторегрессии
m = 5                                                        #количество различных классов{моделей}

q1 = [0.99,   0.0025, 0.0025, 0.0025, 0.0025]
q2 = [0.0025, 0.99,   0.0025, 0.0025, 0.0025]
q3 = [0.0025, 0.0025, 0.99,   0.0025, 0.0025]
q4 = [0.0025, 0.0025, 0.0025, 0.99,   0.0025]
q5 = [0.0025, 0.0025, 0.0025, 0.0025, 0.99]
Q = np.array([q1,q2,q3,q4,q5])                              #матрица вер-ти переходов

curr_t = -1                                                 #текущий номер
x = []                                                      #список для хранения отсчетов

##########################################################################################
############################Блок генератора модельных данных##############################
##########################################################################################

start_x = []                                                #список для стартовых значений

while(curr_t != n-1 ):                                      #начальное наполнение случайными данными
    #x.append(np.random.randn())                             #т.к. AR(n) основывается на n пред.значениях
    start_x.append(np.random.randn())                       #то же самое, но в массиве, не влияющем на x
    curr_t += 1

#Bозможно, что начальное наполнение случайными данными внесет искажения в начале анализа данных, поэтому я
#создаю дополнительный массив, на котором основывается авторегрессия до момента заполнения x n значениями
#N_start = curr_t + 1                                       #номер, с которого начнутся модельные данные
curr_t = -1                                                 #сбрасываем счетчик после наполнения
h_curr = 0                                                  #начальный выбор модели

def generate_number(h_curr):                                #функция генератора
    repers = open('repers_endless.txt', 'a')                #файл точек, где происходит смена модели
    #для смены модели пропорционально вероятности, я решил брать рандомное число, принадлежащее [0,1],
    #разбить этот отрезок на сегменты, равные, собственно, вероятностям и смотреть, в какой сегмент
    #случайное число попало                                          
    factor = np.random.random()
    p_curr = 0
    global curr_t                                           #работаем с глобальным счетчиком отсчетов
    curr_t += 1
    for h_next in range(0,m):
        p_curr += Q[h_curr][h_next]
        if(p_curr >= factor):
            if(h_curr != h_next):
                print('Model change: N', curr_t, h_curr, '-->', h_next)
                repers.write(str(curr_t) + ' ' + str(h_curr) + '\n')        #конец предыдущего сегмента
                repers.write(str(curr_t) + ' ' + str(h_next) + '\n')        #начало следующего
                h_curr = h_next
            break
    #цикл формирования отсчета AR(n)-процесса
    x_curr = phi[h_curr][0]
    for i in range(1,n+1):
        if(curr_t - i >= 0):                                                #проверка на отрицательный
            x_curr += phi[h_curr][i]*x[curr_t - i]                          #индекс
        else:
            x_curr += phi[h_curr][i]*start_x[curr_t - i]                    #используем стартовый массив
            #print('start_x has been used, curr_t = ' + str(curr_t))         #debug
    x_curr += phi[h_curr][3]*np.random.randn()              #шум    
    #заменил random.random() на random.randn() - он имеет нормальное распределение, почему-то стало
                                                                                             #лучше
    x.append(x_curr)
    print(x_curr,'h_curr =',h_curr)
    repers.close()
    return h_curr                                           #возвращаем текущую модель
    
##########################################################################################
############################Блок анализатора данных#######################################
##########################################################################################

def beta(t, h_t1, h_t):                                     #ф-ция beta
    summ = 0                                                #сначала надо посчитать сумму, зав. от x
    for i in range(1,n+1):
        if(t - i >= 0):                                     #проверка на отрицательный индекс                   
            summ += x[t-i]*phi[h_t][i]
        else:
            summ += start_x[t-i]*phi[h_t][i]                #используем массив start_x
    res = (1/(2*phi[h_t][3]))*(x[t] - phi[h_t][0] - summ)**2 - np.log(Q[h_t1][h_t]) #по формуле из статьи
    return res

def d_t(d_t1):                                              #рекуррентный расчет d_t
    res = []
    k_t = []
    for i in range(0,m):                                    #перебор по моделям
        curr_j = []                                         #посчитать для всех j и выбрать min
        for j in range(0,m):                                #перебор по выбору предыдущего
            #beta_curr = beta(curr_t,j,i)
            curr_j.append(d_t1[j] + beta(curr_t,j,i))       #расчет вектора всех значений, среди которых
        res.append(np.min(curr_j))                          #ищется минимум
        k_t.append(np.argmin(curr_j))                       #вектор k_t
    return res, k_t                                         #возвращаем рассчитанные вектора

def g_t(g_t1, k_t):                                         #рекуррентный расчет g_t
    res = []
    for i in range(0,m):
        res.append(g_t1[k_t[i]])
    return res

##########################################################################################
########################Главный цикл выполнения программы#################################
##########################################################################################

#u = N_start - 1                                             #правая граница принятия решений
u = -1
u_prev = -1
#t_special = N_start                                         #особый момент времени    
t_special = 0
K = []                                                      #матрица K
H = []                                                      #искомая сегментация                                              
#начальный вектор d_t0
d_t0 = [-np.log(0.99),-np.log(0.0025),-np.log(0.0025),-np.log(0.0025),-np.log(0.0025)]
g_t0 = []
#debug_summ = 0
for i in range(0,m):                                        #формирование вектора g_t0
    g_t0.append(i)
h_t_11 = g_t0                                               #вектор (11) из статьи, не придумал, как его назвать
#h_curr = generate_number(h_curr)                            #генерируем первое значение, до проверок
for i in range(0,300):                                     #3000 - тест, в конце перейти на while(True)
    h_curr = generate_number(h_curr)                        #передача текущей модели в генератор
    d_t0, k_t_curr = d_t(d_t0)                              #получаем k_t(i) и d_t(i)
    K.append(k_t_curr)                                      #добавляем рассчитанный столбец в матрицу K
    g_t0 = g_t(g_t0, k_t_curr)                              #рекуррентный пересчет g_t
    sp_moment_flag = True
    #g_t_flag = g_t0[0]                                      #будем сравнивать с этим членом все остальные
    for j in range(1,m):                                    #проверка на выполнение условия (16)
        if(g_t0[j] != g_t0[0]):
            sp_moment_flag = False                          #момент точно не особый, выходим из цикла
            break
    if(sp_moment_flag == True):                             #что делать, если момент особый
        print('SPECIAL MOMENT REGISTERED! CURR_T = ' + str(curr_t))
        #debug_summ += 1
        t_special = curr_t
        h_t_2 = h_t_11                                      #начальный вектор для расчетов h_s(i)
        for j in range(1,curr_t+1):                         #вычисляем h_s(i) для отсчетов curr_t-1,...,0
            h_t_1 = []                                          #вектор h_s(i), вычисляемый на новом шаге
            new_u_flag = True                                   #флаг, что найдена новая граница u_t
            for v in range(0,m):
                h_t_1.append(K[curr_t-j - u][h_t_2[v]])
            #h_t_1_flag = h_t_1[0]
            for v in range(1,m):
                if(h_t_1[v] != h_t_1[0]):
                    new_u_flag = False                      #точно не новая граница u_t, выходим из цикла
                    break
            if(new_u_flag == False):
                h_t_2 = h_t_1                               #ищем новую границу дальше
            else:
                u_prev = u                                  #предыдущая граница
                u = curr_t - j                              #новая граница найдена, выходим из цикла
                print('NEW U FOUND: ' + str(u))
                h_u = h_t_1[0]                              #начальное условие для расчета сегментации
                print('SEGMENTATION STARTS: N = ' + str(u) + ' H = ' + str(h_u))
                break
        if(u_prev != u):                                    #для дебага, по идее этого быть не должно
            
            H_curr = []                                         #текущий рассчитанный кусок сегментации
            for j in reversed(range(u_prev+1,u+1)):             #u-последний отсчет, класс которого мы знаем
                h_t_prev = K[j][h_u]                            #классификация эл-та
                H_curr.append(h_t_prev)                         #добавление в массив, которые потом склеится с H
                h_u = h_t_prev                                  #для рекуррентного пересчета h
            H_curr.reverse()                                    #т.к. сегментация была в обратном порядке
            H += H_curr                                         #окончательный построенный отрезок сегментации
            K_new = []                                          #новая таблица K(т.к. нужно сбросить столбцы)
            for j in range(u_prev+1,u+1):
                K_new.append(K[j])
                K = K_new                                           #заменяем урезанной таблицей